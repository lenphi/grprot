{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "8f1773af-9196-4edd-9bde-960149c7eab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import re #regex\n",
    "import pandas as pd\n",
    "import json\n",
    "import requests\n",
    "import pickle\n",
    "import glob\n",
    "import difflib\n",
    "from datetime import datetime\n",
    "from os.path import exists\n",
    "\n",
    "import pdfminer\n",
    "\n",
    "from pdfminer.pdfdocument import PDFDocument\n",
    "from pdfminer.pdfparser import PDFParser\n",
    "from pdfminer.pdfinterp import PDFResourceManager, PDFPageInterpreter\n",
    "from pdfminer.pdfdevice import PDFDevice\n",
    "from pdfminer.pdfpage import PDFPage\n",
    "from pdfminer.layout import LAParams\n",
    "from pdfminer.layout import LTChar\n",
    "from pdfminer.converter import PDFPageAggregator\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "# Verschiedene Funktionen\n",
    "\n",
    "# Load/Save uber_df, nampi_dict and corr_dict\n",
    "def uber_df_load():\n",
    "    with open('uber_df.pickle', 'rb') as f:\n",
    "        return pickle.load(f)\n",
    "\n",
    "def nampi_dict_load():\n",
    "    with open('nampi_dict.pickle', 'rb') as f:\n",
    "        return pickle.load(f)\n",
    "        \n",
    "def uber_df_save():\n",
    "    with open('uber_df.pickle', 'wb') as f:\n",
    "        pickle.dump(uber_df, f, pickle.HIGHEST_PROTOCOL)    \n",
    "\n",
    "def nampi_dict_save():\n",
    "    with open('nampi_dict.pickle', 'wb') as f:\n",
    "        pickle.dump(nampi_dict, f, pickle.HIGHEST_PROTOCOL)  \n",
    "\n",
    "# Lade Liste mit korrekten Namen und Parteien\n",
    "with open(\"list_file.txt\") as f:\n",
    "    name_list = f.read().splitlines()\n",
    "\n",
    "# Funktion,die Namen und Parteien der RednerInnen überprüft und falls nötig korrigiert\n",
    "# Input name = Vorname Name (Partei)\n",
    "# Output: korrekter Name und Partei Vorname Name (Partei)\n",
    "# Code: ChatGPT\n",
    "threshold=0.72\n",
    "def check_name_in_list(name):    \n",
    "    name = name.lstrip()\n",
    "    name = name.split(\")\")[0] + \")\"\n",
    "    if name in name_list:\n",
    "        return name\n",
    "    else:\n",
    "        closest_match = difflib.get_close_matches(name, name_list, n=1, cutoff=threshold)\n",
    "        if closest_match:\n",
    "            if threshold < 0.95:               \n",
    "                return closest_match[0]\n",
    "            else:                \n",
    "                return \"Incorrect\"\n",
    "        else:\n",
    "            return \"Incorrect\"\n",
    "\n",
    "#Variablen zur Nutzung des Gemeinderats-API    \n",
    "endpunkt_suche = 'http://www.gemeinderat-zuerich.ch/api/Mitglieder?'\n",
    "endpunkt_abfrage = 'http://www.gemeinderat-zuerich.ch/api/Mitglieder/details?'\n",
    "\n",
    "# Funktion, welche die PDF files mit pdfminer einliest und RednerInnen und Voten extrahiert und erste Schritte zur Bereinigung vornimmt\n",
    "# Code: ChatGPT\n",
    "def extract_pdf_text(file_name):\n",
    "    from pdfminer.pdfdocument import PDFDocument\n",
    "    from pdfminer.pdfparser import PDFParser\n",
    "    from pdfminer.pdfinterp import PDFResourceManager, PDFPageInterpreter\n",
    "    from pdfminer.pdfdevice import PDFDevice\n",
    "    from pdfminer.pdfpage import PDFPage\n",
    "    from pdfminer.layout import LAParams\n",
    "    from pdfminer.converter import PDFPageAggregator\n",
    "    \n",
    "    print(file_name)\n",
    "   \n",
    "    # Open the PDF file\n",
    "    fp = open(file_name, 'rb')\n",
    "\n",
    "    # Create a PDF parser object associated with the file object\n",
    "    parser = PDFParser(fp)\n",
    "\n",
    "    # Create a PDF document object that stores the document structure\n",
    "    document = PDFDocument(parser)\n",
    "\n",
    "    # Create a PDF resource manager object that stores shared resources\n",
    "    rsrcmgr = PDFResourceManager()\n",
    "\n",
    "    # Set parameters for analysis\n",
    "    laparams = LAParams()\n",
    "\n",
    "    # Create a PDF page aggregator object\n",
    "    device = PDFPageAggregator(rsrcmgr, laparams=laparams)\n",
    "    interpreter = PDFPageInterpreter(rsrcmgr, device)\n",
    "\n",
    "    # Save the output of the code to a list\n",
    "    output = []\n",
    "    for page in PDFPage.create_pages(document):\n",
    "        interpreter.process_page(page)\n",
    "        layout = device.get_result()\n",
    "        for obj in layout:\n",
    "            if hasattr(obj, \"get_text\"):\n",
    "                for line in obj:\n",
    "                    for char in line:\n",
    "                        if isinstance(char, LTChar):\n",
    "                            output.append((char.get_text(), char.fontname))\n",
    "\n",
    "    # Process the output word by word\n",
    "    bold_word = \"\"\n",
    "    italic_word = \"\"\n",
    "    nested_list = []\n",
    "    previous_font = \"\"\n",
    "\n",
    "    for char, font in output:\n",
    "        if \"Arial-BoldItalicMT\" in font:\n",
    "            if \"Arial-ItalicMT\" in previous_font:\n",
    "                nested_list.append([bold_word, italic_word])\n",
    "                bold_word = \"\"\n",
    "                italic_word = \"\"\n",
    "            bold_word += char\n",
    "            previous_font = font\n",
    "        elif \"Arial-ItalicMT\" in font:\n",
    "            italic_word += char\n",
    "            previous_font = font\n",
    "        else:\n",
    "            if bold_word:\n",
    "                nested_list.append([bold_word, italic_word])\n",
    "                bold_word = \"\"\n",
    "                italic_word = \"\"\n",
    "\n",
    "    # Check if there's any remaining text that needs to be added to the list\n",
    "    if bold_word:\n",
    "        nested_list.append([bold_word, italic_word])\n",
    "\n",
    "    # If the first element of a sublist is empty, but the second element isnt, add that to the second element of the previous sublist\n",
    "    final_list = []\n",
    "    for i in range(len(nested_list)):\n",
    "        stripped_first_elem = nested_list[i][0].strip()\n",
    "        if stripped_first_elem.startswith(\"ST\") or stripped_first_elem.startswith(\"Ratspräsident\") or stripped_first_elem.startswith('Pierre Heusser') or stripped_first_elem.startswith(\"Vizepräsident\") or stripped_first_elem.startswith('Pierre Heusser') or any(char.isdigit() for char in stripped_first_elem) == True:\n",
    "            continue\n",
    "            \n",
    "        elif nested_list[i][0].strip() == \"\" and nested_list[i][1].strip() != \"\":\n",
    "            if final_list:\n",
    "                final_list[-1][1] += nested_list[i][1]\n",
    "        \n",
    "        elif nested_list[i][0].strip() == \":\" and nested_list[i][1].strip() != \"\":\n",
    "            if final_list:\n",
    "                final_list[-1][1] += nested_list[i][1] \n",
    "                \n",
    "        elif nested_list[i][0].strip() == \".\":\n",
    "            if final_list:\n",
    "                final_list[-1][1] += nested_list[i][1]\n",
    "    \n",
    "        elif nested_list[i][0].strip() == \".\":\n",
    "            if final_list:\n",
    "                final_list[-1][1] += nested_list[i][1]\n",
    "        \n",
    "        elif nested_list[i][0].strip() != \"\" and nested_list[i][0][:2] != \"ST\":\n",
    "\n",
    "            final_list.append(nested_list[i])\n",
    "        \n",
    "    # Delete spaces at the beginning of the second element of every sublist\n",
    "    for i in range(len(final_list)):\n",
    "        final_list[i][1] = final_list[i][1].lstrip()\n",
    "        \n",
    "    # Delete \"Dr.\" ...\n",
    "    for i in range(len(final_list)):\n",
    "        final_list[i][0] = final_list[i][0].replace('Dr.', '')    \n",
    "        \n",
    "    final_list = [sublist for sublist in final_list if len(sublist[0]) >= 10]       \n",
    "\n",
    "    return final_list\n",
    "\n",
    "       \n",
    "#Funktion, die aus der vorangehenden nested list mit den Voten ein erstes dataframe erstellt\n",
    "def build_initial_df (votelist):\n",
    "    df = pd.DataFrame(votelist)\n",
    "    return df\n",
    "\n",
    "#Funktion, welches die Textlängen der Voten zum df hinzufügt\n",
    "def add_length (intitial_df):   \n",
    "    initial_df['Länge'] = initial_df[1].apply(lambda x: len (x)) # Len ermitteln und neue Spalte bilden\n",
    "    return initial_df    \n",
    "\n",
    "#Funktion, welche die noch in den Namen enthaltenen Parteien absplittet und in eine eigene Spalte im df schiebt. Bereinigung einzelner Sonderfälle. \n",
    "def split_parties (df_with_length):\n",
    "    parteien = []\n",
    "    for values in df_with_length[0]:\n",
    "        #if values == 'David Garcia Nuñez':\n",
    "            #values = 'David Garcia Nuñez (AL)'\n",
    "        #elif values == 'Walter Anken':\n",
    "            #values = 'Walter Anken (SVP)'\n",
    "        #elif values == 'Sven Sobernheim':\n",
    "            #values = 'Sven Sobernheim (GLP)'               \n",
    "        \n",
    "        parteien.append(re.search(r'(?<=\\()(.+?)(?=\\))', values).group())\n",
    "    \n",
    "    df_with_length['Partei'] = parteien\n",
    "    \n",
    "    for values in df_with_length[0]:\n",
    "        if '(' in values and ')' in values:\n",
    "            partei = (re.search(r'(?<=\\()(.+?)(?=\\))', values))[1]\n",
    "            name_neu = values.replace('('+partei+')', '')\n",
    "            name_neu = name_neu.replace(':','')\n",
    "            name_neu = name_neu.strip()\n",
    "            name_ohne_partei.append(name_neu)\n",
    "        else:\n",
    "            name_neu = values.strip()\n",
    "            name_ohne_partei.append(name_neu)\n",
    "        \n",
    "    df_with_length[0] = name_ohne_partei\n",
    "    df_with_length[0] = df_with_length[0].str.strip()\n",
    "    \n",
    "    return df_with_length\n",
    "    \n",
    "#Funktion, welche die Namen der RednerInnen aus dem df für die API-Abfrage aufbereitet\n",
    "def build_searchlist (df_with_corrnames):\n",
    "    search_list = []\n",
    "    names = df_with_corrnames[0].values.tolist()\n",
    "    names = [x.replace(' ','+') for x in names] # Space durch + ersetzen\n",
    "    parties = df_with_corrnames['Partei'].values.tolist()\n",
    "    search_list.extend([list(a) for a in zip(names, parties)])\n",
    "    return search_list\n",
    "\n",
    "# Suchabfrage nach Name\n",
    "# Das API ignoriert exakte Namen und Parteizugehörigtkeit und kann deshalbe falsche Treffer zurückgeben.\n",
    "def membersearch(name, partei):    \n",
    "    name = name.strip()\n",
    "    #if 'M ichael Schmid' in name:\n",
    "        #name.replace('M ichael Schmid', 'Michael Schmid')\n",
    "    pre_filtered = []\n",
    "    req = endpunkt_suche+'name='+name+'&parteiId='+partei+'&includeInactive=true'\n",
    "    r_suche = requests.get(req)\n",
    "    r_suche_out = r_suche.json()\n",
    "    for every in r_suche_out:\n",
    "        if every['Partei'] == partei:\n",
    "            pre_filtered.append(every)\n",
    "    \n",
    "    return pre_filtered    \n",
    "\n",
    "# Funktion die Suchresultate validiert  - welcher Name stimmt wirklich? \n",
    "# Es wird überprüft, ob Name und Partei des API-Resultats tatsächlich dem Input entspricht\n",
    "# Ausgegeben wird die MID des API, welches jedes Ratsmitglied eindeutig identifziert\n",
    "def memberselect (searchresult):\n",
    "    for every_result in searchresult:        \n",
    "        resname = every_result['Vorname']+' '+every_result['Name']        \n",
    "        snamrep = searchname.replace('+',' ')        \n",
    "        if resname == snamrep:        \n",
    "            corrid = every_result['Id']\n",
    "            return corrid\n",
    "\n",
    "# Funktion, die Mitgliederdetails anhand der ermittelten korrekten MID abfragt\n",
    "# Ausgeben wird eine Liste mit Anrede, Vorname, Name, Partei, Geburtstag, MID, sowie (zur Kontrolle) Name und Partei gemäss dataframe mit den Voten\n",
    "def memberget (mid):\n",
    "    type(mid)\n",
    "    url = endpunkt_abfrage+'mid='+mid\n",
    "    r = requests.get(url)\n",
    "    out = r.json()\n",
    "    vorname = out['Vorname']\n",
    "    name = out['Name']\n",
    "    partei = out['Partei']\n",
    "    nampi = vorname+' ' +name+partei\n",
    "    put = [out['Anrede'], out['Vorname'], out['Name'], out['Partei'], out['Geburtstag'], out['Id'], nampi]\n",
    "    \n",
    "    return put\n",
    "\n",
    "# Funktion, welche eine lokale Datenbank mit bereits früher abgefragten Mitgliederdetails abfragt. \n",
    "def query_nampi_dict (name,partei):\n",
    "    nampi = name+partei\n",
    "    output = nampi_dict[nampi]\n",
    "    return output\n",
    "\n",
    "# Funktion, welche einzelne Schritte/Funktionen zur Abfrage von Mitgliederdetails bündelt (check_nampi, quey_nampi, membersearch, memberselect und memberget)\n",
    "# Ausgegeben Ausgeben wird eine Liste [Anrede, Vorname, Name, Partei, Geburtstag, MID, Name und Partei gemäss dataframe mit den Voten]\n",
    "# Details zu jedem Ratsmitglied werden laufend in eine lokale Datenbank gespeichert\n",
    "# Die lokale Datenbank wird bei der Abfrage bevorzugt, da das API sehr träge ist. So wird jedes Mitglied nur ein einziges Mal über das API abgefragt.\n",
    "def membquest(name, partei):\n",
    "    name = name.replace(':', '')\n",
    "    name = name.strip()  \n",
    "    if partei == 'FPD':\n",
    "        partei = 'FDP'\n",
    "    nampi = name+partei\n",
    "    if nampi in nampi_dict:\n",
    "        put = query_nampi_dict (name, partei)\n",
    "        \n",
    "    else:\n",
    "        searchres = membersearch (name, partei)\n",
    "        midn = memberselect (searchres)    \n",
    "        put = memberget (midn)\n",
    "        nampi = name+partei\n",
    "        nampi_dict[nampi]=put\n",
    "    return put\n",
    "\n",
    "#Funktion, welche das bereits vorhandene df mit Voten, RednerInne, Längen, etc. aufräumt\n",
    "def clean_final_df (final_df):\n",
    "    final_df = final_df.iloc[:, [4,0,3,5,1,2,6,7]] # Reihenfolge der columns\n",
    "    final_df.columns = ['Anrede', 'Name', 'Partei', 'Geburtsdatum', 'Votum', 'Länge', 'Id', 'nampi'] # Beschriftung columns\n",
    "    final_df['Geburtsdatum'] =  pd.to_datetime(final_df['Geburtsdatum'], infer_datetime_format=True) # Geburtsdatum richtig setzen\n",
    "    return final_df    \n",
    "\n",
    "###\n",
    "def readprot(prot_filename):\n",
    "    global sitzungs_id\n",
    "    sitzungs_id = ''.join(re.findall(r'[0-9]', prot_filename))\n",
    "    with open(prot_filename, 'r') as jsprot:\n",
    "        prot = json.load(jsprot)\n",
    "        return prot\n",
    "    \n",
    "\n",
    "#Funktion, welche die Voten jeder einzelnen Sitzung zu Kontrollzwecken in ein File speichert\n",
    "def save_vote_df (df):\n",
    "    with open('vote_dfs/'+sitzungs_id+'.pickle', 'wb') as f:\n",
    "        pickle.dump(df, f, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "\n",
    "def save_votelist(votelist):\n",
    "    with open('votelists/'+sitzungs_id+'.pickle', 'wb') as f:\n",
    "              pickle.dump(votelist, f, pickle.HIGHEST_PROTOCOL)\n",
    "            \n",
    "#Erstellt eine Liste der Protokoll-Files, die eingelesen werden sollen            \n",
    "list_of_pdfs = sorted(glob.glob('2018/*.pdf'))\n",
    "\n",
    "#Erstellt eine Liste der Protokoll-Files, die eingelesen werden sollen\n",
    "list_of_json = sorted(glob.glob('betatest/*.json'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "871e9bef-a68d-4b2a-ba6d-541c0037bc68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018/GR-Protokoll 20180516.001 substanziell.pdf\n",
      "2018/GR-Protokoll 20180523.002 substanziell.pdf\n",
      "2018/GR-Protokoll 20180530.003 substanziell.pdf\n",
      "2018/GR-Protokoll 20180606.004 substanziell.pdf\n",
      "2018/GR-Protokoll 20180613.005 substanziell.pdf\n",
      "2018/GR-Protokoll 20180620.006 substanziell.pdf\n",
      "2018/GR-Protokoll 20180627.007 substanziell.pdf\n",
      "2018/GR-Protokoll 20180704.008 substanziell.pdf\n",
      "2018/GR-Protokoll 20180711.009 substanziell.pdf\n",
      "2018/GR-Protokoll 20180711.010 substanziell.pdf\n",
      "2018/GR-Protokoll 20180822.011 substanziell.pdf\n",
      "2018/GR-Protokoll 20180829.012 substanziell.pdf\n",
      "2018/GR-Protokoll 20180905.013 substanziell.pdf\n",
      "2018/GR-Protokoll 20180912.014 substanziell.pdf\n",
      "2018/GR-Protokoll 20180919.015 substanziell.pdf\n",
      "2018/GR-Protokoll 20180926.016 substanziell.pdf\n",
      "2018/GR-Protokoll 20181003.017 substanziell.pdf\n",
      "2018/GR-Protokoll 20181024.018 substanziell.pdf\n",
      "2018/GR-Protokoll 20181031.019 substanziell.pdf\n",
      "2018/GR-Protokoll 20181107.020 substanziell.pdf\n",
      "2018/GR-Protokoll 20181114.021 substanziell.pdf\n",
      "2018/GR-Protokoll 20181114.022 substanziell.pdf\n",
      "2018/GR-Protokoll 20181121.023 substanziell.pdf\n",
      "2018/GR-Protokoll 20181128.024 substanziell.pdf\n",
      "2018/GR-Protokoll 20181205.025 substanziell.pdf\n",
      "2018/GR-Protokoll 20181212.026 substanziell.pdf\n",
      "2018/GR-Protokoll 20181212.027 substanziell.pdf\n",
      "2018/GR-Protokoll 20181212.028 substanziell.pdf\n",
      "2018/GR-Protokoll 20181214.029 substanziell.pdf\n",
      "2018/GR-Protokoll 20181214.030 substanziell.pdf\n",
      "2018/GR-Protokoll 20181214.031 substanziell.pdf\n",
      "2018/GR-Protokoll 20181219.032 substanziell.pdf\n",
      "2018/GR-Protokoll 20190109.033 substanziell.pdf\n",
      "2018/GR-Protokoll 20190116 034 substanziell.pdf\n",
      "2018/GR-Protokoll 20190123.035 substanziell.pdf\n",
      "2018/GR-Protokoll 20190130.036 substanziell.pdf\n",
      "2018/GR-Protokoll 20190130.037 substanziell.pdf\n",
      "2018/GR-Protokoll 20190206.038 substanziell.pdf\n",
      "2018/GR-Protokoll 20190227.039 substanziell.pdf\n",
      "2018/GR-Protokoll 20190306.040 substanziell.pdf\n",
      "2018/GR-Protokoll 20190313.041 substanziell.pdf\n",
      "2018/GR-Protokoll 20190320.042 substanziell.pdf\n",
      "2018/GR-Protokoll 20190327.043 substanziell.pdf\n",
      "2018/GR-Protokoll 20190403.044 substanziell.pdf\n",
      "2018/GR-Protokoll 20190410.045 substanziell.pdf\n",
      "2018/GR-Protokoll 20190417.046 substanziell.pdf\n",
      "2018/GR-Protokoll 20190515.048 substanziell.pdf\n",
      "2018/GR-Protokoll 20190522.049 substanziell.pdf\n",
      "2018/GR-Protokoll 20190605.050 substanziell.pdf\n",
      "2018/GR-Protokoll 20190612.051 substanziell.pdf\n",
      "2018/GR-Protokoll 20190619.052 substanziell.pdf\n",
      "2018/GR-Protokoll 20190619.053 substanziell.pdf\n",
      "2018/GR-Protokoll 20190626.054 substanziell.pdf\n",
      "2018/GR-Protokoll 20190703.055 substanziell.pdf\n",
      "2018/GR-Protokoll 20190703.056 substanziell.pdf\n",
      "2018/GR-Protokoll 20190710.057 substanziell.pdf\n",
      "2018/GR-Protokoll 20190710.058 substanziell.pdf\n",
      "2018/GR-Protokoll 20190821.059 substanziell.pdf\n",
      "2018/GR-Protokoll 20190828.060 substanziell.pdf\n",
      "2018/GR-Protokoll 20190904.061 substanziell.pdf\n",
      "2018/GR-Protokoll 20190911.062 substanziell.pdf\n",
      "2018/GR-Protokoll 20190918.063 substanziell.pdf\n",
      "2018/GR-Protokoll 20190925.064 substanziell.pdf\n",
      "2018/GR-Protokoll 20190925.065 substanziell.pdf\n",
      "2018/GR-Protokoll 20190925.066 substanziell.pdf\n",
      "2018/GR-Protokoll 20191002.067 substanziell.pdf\n",
      "2018/GR-Protokoll 20191023.068 substanziell.pdf\n",
      "2018/GR-Protokoll 20191030.069 substanziell.pdf\n",
      "2018/GR-Protokoll 20191030.070 substanziell.pdf\n",
      "2018/GR-Protokoll 20191106.071 substanziell.pdf\n",
      "2018/GR-Protokoll 20191113.072 substanziell.pdf\n",
      "2018/GR-Protokoll 20191113.073 substanziell.pdf\n",
      "2018/GR-Protokoll 20191120.074 substanziell.pdf\n",
      "2018/GR-Protokoll 20191127.075 substanziell.pdf\n",
      "2018/GR-Protokoll 20191127.076 substanziell.pdf\n",
      "2018/GR-Protokoll 20191204.077 substanziell.pdf\n",
      "2018/GR-Protokoll 20191211.078 substanziell.pdf\n",
      "2018/GR-Protokoll 20191211.079 substanziell.pdf\n",
      "2018/GR-Protokoll 20191211.080 substanziell.pdf\n",
      "2018/GR-Protokoll 20191213.081 substanziell.pdf\n",
      "2018/GR-Protokoll 20191213.082 substanziell.pdf\n",
      "2018/GR-Protokoll 20191213.083 substanziell.pdf\n",
      "2018/GR-Protokoll 20191218.084 substanziell.pdf\n",
      "2018/GR-Protokoll 20200108.085 substanziell.pdf\n",
      "2018/GR-Protokoll 20200115.086 substanziell.pdf\n",
      "2018/GR-Protokoll 20200122.087 substanziell.pdf\n",
      "2018/GR-Protokoll 20200129.088 substanziell.pdf\n",
      "2018/GR-Protokoll 20200129.089 substanziell.pdf\n",
      "2018/GR-Protokoll 20200205.090 substanziell.pdf\n",
      "2018/GR-Protokoll 20200226.091 substanziell.pdf\n",
      "2018/GR-Protokoll 20200304.092 substanziell.pdf\n",
      "2018/GR-Protokoll 20200506.094 substanziell.pdf\n",
      "2018/GR-Protokoll 20200513.095 substanziell.pdf\n",
      "2018/GR-Protokoll 20200527.096 substanziell.pdf\n",
      "2018/GR-Protokoll 20200603.097 substanziell.pdf\n",
      "2018/GR-Protokoll 20200610.098 substanziell.pdf\n",
      "2018/GR-Protokoll 20200617.099 substanziell.pdf\n",
      "2018/GR-Protokoll 20200624.100 substanziell.pdf\n",
      "2018/GR-Protokoll 20200701.101 substanziell.pdf\n",
      "2018/GR-Protokoll 20200708.102 substanziell.pdf\n",
      "2018/GR-Protokoll 20200708.103 substanziell.pdf\n",
      "2018/GR-Protokoll 20200819.104 substanziell.pdf\n",
      "2018/GR-Protokoll 20200826.105 substanziell.pdf\n",
      "2018/GR-Protokoll 20200902.106 substanziell.pdf\n",
      "2018/GR-Protokoll 20200909.107 substanziell.pdf\n",
      "2018/GR-Protokoll 20200923.108 substanziell.pdf\n",
      "2018/GR-Protokoll 20200930.109 substanziell.pdf\n",
      "2018/GR-Protokoll 20200930.110 substanziell.pdf\n",
      "2018/GR-Protokoll 20201021.111 substanziell.pdf\n",
      "2018/GR-Protokoll 20201028.112 substanziell.pdf\n",
      "2018/GR-Protokoll 20201104.113 substanziell.pdf\n",
      "2018/GR-Protokoll 20201111.114 substanziell.pdf\n",
      "2018/GR-Protokoll 20201118.115 substanziell.pdf\n",
      "2018/GR-Protokoll 20201125.116 substanziell.pdf\n",
      "2018/GR-Protokoll 20201202.117 substanziell.pdf\n",
      "2018/GR-Protokoll 20201209.118 substanziell.pdf\n",
      "2018/GR-Protokoll 20201209.119 substanziell.pdf\n",
      "2018/GR-Protokoll 20201209.120 substanziell.pdf\n",
      "2018/GR-Protokoll 20201211.121 substanziell.pdf\n",
      "2018/GR-Protokoll 20201211.122 substanziell.pdf\n",
      "2018/GR-Protokoll 20201211.123 substanziell.pdf\n",
      "2018/GR-Protokoll 20201216.124 substanziell.pdf\n",
      "2018/GR-Protokoll 20201216.125 substanziell.pdf\n",
      "2018/GR-Protokoll 20201216.126 substanziell.pdf\n",
      "2018/GR-Protokoll 20210106.127 substanziell.pdf\n",
      "2018/GR-Protokoll 20210113.128 substanziell.pdf\n",
      "2018/GR-Protokoll 20210120.129 substanziell.pdf\n",
      "2018/GR-Protokoll 20210127.130 substanziell.pdf\n",
      "2018/GR-Protokoll 20210203.131 substanziell.pdf\n",
      "2018/GR-Protokoll 20210210.132 substanziell.pdf\n",
      "2018/GR-Protokoll 20210303.133 substanziell.pdf\n",
      "2018/GR-Protokoll 20210310.134 substanziell.pdf\n",
      "2018/GR-Protokoll 20210317.135 substanziell.pdf\n",
      "2018/GR-Protokoll 20210324.136 substanziell.pdf\n",
      "2018/GR-Protokoll 20210331.137 substanziell.pdf\n",
      "2018/GR-Protokoll 20210407.138 substanziell.pdf\n",
      "2018/GR-Protokoll 20210407.139 substanziell.pdf\n",
      "2018/GR-Protokoll 20210407.140 substanziell.pdf\n",
      "2018/GR-Protokoll 20210409.141 substanziell.pdf\n",
      "2018/GR-Protokoll 20210409.142 substanziell.pdf\n",
      "2018/GR-Protokoll 20210410.143 substanziell.pdf\n",
      "2018/GR-Protokoll 20210410.144 substanziell.pdf\n",
      "2018/GR-Protokoll 20210414.145 substanziell.pdf\n",
      "2018/GR-Protokoll 20210421.146 substanziell.pdf\n",
      "2018/GR-Protokoll 20210519.147 substanziell.pdf\n",
      "2018/GR-Protokoll 20210526.148 substanziell.pdf\n",
      "2018/GR-Protokoll 20210602.149 substanziell.pdf\n",
      "2018/GR-Protokoll 20210609.150 substanziell.pdf\n",
      "2018/GR-Protokoll 20210616.151 substanziell.pdf\n",
      "2018/GR-Protokoll 20210623.152 substanziell.pdf\n",
      "2018/GR-Protokoll 20210630.153 substanziell.pdf\n",
      "2018/GR-Protokoll 20210630.154 substanziell.pdf\n",
      "2018/GR-Protokoll 20210630.155 substanziell.pdf\n",
      "2018/GR-Protokoll 20210702.156 substanziell.pdf\n",
      "2018/GR-Protokoll 20210707.157 substanziell.pdf\n",
      "2018/GR-Protokoll 20210714.158 substanziell.pdf\n",
      "2018/GR-Protokoll 20210714.159 substanziell.pdf\n",
      "2018/GR-Protokoll 20210825.160 substanziell.pdf\n",
      "2018/GR-Protokoll 20210901.161 substanziell.pdf\n",
      "2018/GR-Protokoll 20210908.162 substanziell.pdf\n",
      "2018/GR-Protokoll 20210915.163 substanziell.pdf\n",
      "2018/GR-Protokoll 20210922.164 substanziell.pdf\n",
      "2018/GR-Protokoll 20210929.165 substanziell.pdf\n",
      "2018/GR-Protokoll 20211006.166 substanziell.pdf\n",
      "2018/GR-Protokoll 20211027.167 substanziell.pdf\n",
      "2018/GR-Protokoll 20211103.168 substanziell.pdf\n",
      "2018/GR-Protokoll 20211110.169 substanziell.pdf\n",
      "2018/GR-Protokoll 20211117.170 substanziell.pdf\n",
      "2018/GR-Protokoll 20211124.171 substanziell.pdf\n",
      "2018/GR-Protokoll 20211201.172 substanziell.pdf\n",
      "2018/GR-Protokoll 20211208.173 substanziell.pdf\n",
      "2018/GR-Protokoll 20211208.174 substanziell.pdf\n",
      "2018/GR-Protokoll 20211208.175 substanziell.pdf\n",
      "2018/GR-Protokoll 20211210.176 substanziell.pdf\n",
      "2018/GR-Protokoll 20211210.177 substanziell.pdf\n",
      "2018/GR-Protokoll 20211210.178 substanziell.pdf\n",
      "2018/GR-Protokoll 20211215.179 substanziell.pdf\n",
      "2018/GR-Protokoll 20220105.180 substanziell.pdf\n",
      "2018/GR-Protokoll 20220112.181 substanziell.pdf\n",
      "2018/GR-Protokoll 20220126.183 substanziell.pdf\n",
      "2018/GR-Protokoll 20220202.184 substanziell.pdf\n",
      "2018/GR-Protokoll 20220209.185 substanziell.pdf\n",
      "2018/GR-Protokoll 20220302.186 substanziell.pdf\n",
      "2018/GR-Protokoll 20220309.187 substanziell.pdf\n",
      "2018/GR-Protokoll 20220316.188 substanziell.pdf\n",
      "2018/GR-Protokoll 20220319.189 substanziell.pdf\n",
      "2018/GR-Protokoll 20220319.190 substanziell.pdf\n",
      "2018/GR-Protokoll 20220323.191 substanziell.pdf\n",
      "2018/GR-Protokoll 20220330.192 substanziell.pdf\n",
      "2018/GR-Protokoll 20220406.193 substanziell.pdf\n",
      "2018/GR-Protokoll 20220413.194 substanziell.pdf\n"
     ]
    }
   ],
   "source": [
    "# Lade (falls vorhanden) oder initialisiere uber_df, das df mit den Endresultaten\n",
    "if exists('uber_df.pickle') == True:\n",
    "    uber_df = uber_df_load()\n",
    "else:\n",
    "    uber_df = pd.DataFrame(columns=['Anrede','Name','Partei','Geburtsdatum','Sitzung','Länge','Id', 'nampi'])\n",
    "\n",
    "# Lade oder initialisere nampi_dict, die lokale Datenbank mit Details zu den Ratsmitgliedern\n",
    "if exists('nampi_dict.pickle') == True:\n",
    "    nampi_dict = nampi_dict_load()\n",
    "else:\n",
    "    nampi_dict = {} # key=nampi value=list'Anrede', 'Vorname', 'Name', 'Partei', 'Geburtstag', 'Id'\n",
    "\n",
    "# Bündelt verschiedene Funktionen\n",
    "# Ausgegeben wird eine Liste von RednerInnen, deren Details abgefragt werden müssen sowie (mittels 'global') ein df mit den Voten und RednerInnen\n",
    "def part1 (every_pdf):\n",
    "    global sitzungs_id\n",
    "    sitzungs_id = ''.join(re.findall(r'[0-9]', every_pdf))\n",
    "    \n",
    "    final_list=extract_pdf_text(every_pdf)\n",
    "    \n",
    "    for i in range(len(final_list)):\n",
    "        final_list[i][0] = check_name_in_list(final_list[i][0])\n",
    "    \n",
    "    votelist = final_list\n",
    "    #save_votelist (votelist)\n",
    "        \n",
    "    global initial_df\n",
    "    initial_df = pd.DataFrame(votelist)\n",
    "    #initial_df = initial_df[initial_df[0].apply(lambda x: not x.startswith('ST'))]\n",
    "    #initial_df = initial_df[initial_df[0].apply(lambda x: not x.startswith('Pierre Heusser'))]\n",
    "    \n",
    "    #initial_df[0] = initial_df[0].apply(lambda x: x.replace(' :', ''))\n",
    "    #initial_df[0] = initial_df[0].apply(lambda x: x.replace(':', ''))\n",
    "    #initial_df[0] = initial_df[0].apply(lambda x: x.replace(' nimmt Stellung', ''))\n",
    "        \n",
    "    df_with_length = add_length(initial_df)\n",
    "    #save_vote_df(df_with_length)\n",
    "    \n",
    "    global name_ohne_partei\n",
    "    name_ohne_partei =[]\n",
    "    \n",
    "    global df_in_progress\n",
    "    df_in_progress = split_parties (df_with_length)\n",
    "       \n",
    "    search_list = build_searchlist (df_in_progress)\n",
    "    return search_list\n",
    "\n",
    "# Schlaufe, welche eine Liste mit den PDFs abarbeitet. \n",
    "# Endresultat ist das df mit allen Voten sowie Infos zu deren Länge und den RednerInnen\n",
    "for every_pdf in list_of_pdfs:\n",
    "    search_list = part1 (every_pdf)\n",
    "    resultlist = []\n",
    "    for every_name in search_list:\n",
    "        global searchname\n",
    "        searchname = every_name[0]\n",
    "        searchpartei = every_name[1]\n",
    "        outp = membquest (searchname, searchpartei)\n",
    "        resultlist.append(outp)\n",
    "        \n",
    "    nampi_dict_save()\n",
    "    \n",
    "    result_df = pd.DataFrame(resultlist)    \n",
    "    result_df.drop(columns=[1,2,3], inplace=True)\n",
    "    final_df = pd.concat([df_in_progress, result_df], axis=1)\n",
    "    final_df = clean_final_df(final_df)\n",
    "    move_df = final_df.copy(deep=True)\n",
    "    \n",
    "    # Prep to move to uber_df\n",
    "    move_df.insert(4,'Sitzung','')\n",
    "    move_df['Sitzung'] = sitzungs_id\n",
    "    move_df.drop(['Votum'], axis=1, inplace=True)\n",
    "    \n",
    "    # !!! Index ist noch falsch, nicht fortlaufend\n",
    "    uber_df = uber_df.append(move_df)\n",
    "    #uber_df.reset_index()\n",
    "    uber_df_save()\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1575448c-88e5-4b7f-b034-3df9829cd394",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b32a563-f51e-4684-9ee6-ab034b1f40ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_with_corrnames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76ec90e7-d349-4fba-8db0-194247b2a5ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "uber_df[uber_df['Name'].str.contains(\"Strub\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95c32664-9bf9-47f2-86a5-d876523dc6ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_with_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4199d552-90ae-492f-a69c-286f45a6fc9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "uber_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4401c4c-8d8f-45a2-b1b6-1ec8f15b040b",
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped = uber_df.groupby('Anrede')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc43f9eb-6265-43ce-a114-c09d41512042",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = grouped['Länge'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84a9a7e9-4203-4c9e-838c-3251b25440f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d45c3df-be31-45c9-8043-869f8722cb34",
   "metadata": {},
   "outputs": [],
   "source": [
    "result.sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c4024c3-214f-4ab5-8627-8765ce5e54f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "'Christoph Marty (SVP) nimmt Stellung'.split(\")\")[0] + \")\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1057d113-f352-4e08-a70a-f9b470d9365d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
