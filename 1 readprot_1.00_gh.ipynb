{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "65d94154-628e-4913-91c8-f4bcc309507d",
   "metadata": {},
   "source": [
    "# Readprot 1.0\n",
    "Extrahiert aus den PDF-Protokollen im Verzeichnis '2018' alle Voten und ordnet sie dem/der jeweiligen RednerIn zu.\n",
    "Das Ergebnis-Dataframe wird gespeichert für die Auswertung."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9012751f-0c32-4158-ad30-2b81298ea34b",
   "metadata": {},
   "source": [
    "## 1 - Libraries, Variablen und Funktionen"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8a043e8-aaec-444d-b229-86ded40a323c",
   "metadata": {},
   "source": [
    "### 1.1 Import\n",
    "Bennötigt werden regex, pandas, json, requests, pickle, glob, difflib, datetime, os.path und pdfminer. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "781d32b0-30d1-41e6-b1e8-febeae90411a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re #regex\n",
    "import pandas as pd\n",
    "import json\n",
    "import requests\n",
    "import pickle\n",
    "import glob\n",
    "import difflib\n",
    "from datetime import datetime\n",
    "from os.path import exists\n",
    "\n",
    "import pdfminer\n",
    "from pdfminer.pdfdocument import PDFDocument\n",
    "from pdfminer.pdfparser import PDFParser\n",
    "from pdfminer.pdfinterp import PDFResourceManager, PDFPageInterpreter\n",
    "from pdfminer.pdfdevice import PDFDevice\n",
    "from pdfminer.pdfpage import PDFPage\n",
    "from pdfminer.layout import LAParams\n",
    "from pdfminer.layout import LTChar\n",
    "from pdfminer.converter import PDFPageAggregator\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca9e4985-cd98-46e8-b0cf-991948902a32",
   "metadata": {},
   "source": [
    "### 1.2 Variablen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64ccc461-a25a-4dde-91fa-2ef4227cd86f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Variablen zur Nutzung des Gemeinderats-API    \n",
    "endpunkt_suche = 'http://www.gemeinderat-zuerich.ch/api/Mitglieder?'\n",
    "endpunkt_abfrage = 'http://www.gemeinderat-zuerich.ch/api/Mitglieder/details?'\n",
    "\n",
    "#Erstellt eine Liste der Protokoll-Files, die eingelesen werden sollen            \n",
    "list_of_pdfs = sorted(glob.glob('2018/*.pdf'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5261958-50cf-4151-b20e-126aaf17902e",
   "metadata": {},
   "source": [
    "### 1.3.1 Hilfsfunktionen\n",
    "verschiedene kleinere Funktionen, die später benötigt werden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59db2d05-08be-4182-a716-faf6e4f9fbce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load/Save uber_df, nampi_dict and corr_dict\n",
    "def uber_df_load():\n",
    "    with open('uber_df.pickle', 'rb') as f:\n",
    "        return pickle.load(f)\n",
    "\n",
    "def nampi_dict_load():\n",
    "    with open('nampi_dict.pickle', 'rb') as f:\n",
    "        return pickle.load(f)\n",
    "        \n",
    "def uber_df_save():\n",
    "    with open('uber_df.pickle', 'wb') as f:\n",
    "        pickle.dump(uber_df, f, pickle.HIGHEST_PROTOCOL)    \n",
    "\n",
    "def nampi_dict_save():\n",
    "    with open('nampi_dict.pickle', 'wb') as f:\n",
    "        pickle.dump(nampi_dict, f, pickle.HIGHEST_PROTOCOL)\n",
    "        \n",
    "#Funktion, welche die Voten jeder einzelnen Sitzung zu Kontrollzwecken in ein File speichert\n",
    "def save_votelist(votelist):\n",
    "    with open('votelists/'+sitzungs_id+'.pickle', 'wb') as f:\n",
    "              pickle.dump(votelist, f, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12415972-8e0a-4b50-9c90-a692c747d9be",
   "metadata": {},
   "source": [
    "### 1.3.2 Kernfunktionen\n",
    "Funktion für das Einlesen der Protokolle sowie für die Überprüfung der Namen der RednerInnen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8086ae28-9d62-47d7-a0fb-dcea5dc4bed9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funktion, welche die PDF files mit pdfminer einliest und RednerInnen und Voten extrahiert und erste Schritte zur Bereinigung vornimmt\n",
    "# Code: ChatGPT\n",
    "def extract_pdf_text(file_name):\n",
    "      \n",
    "    print(file_name)\n",
    "   \n",
    "    # Open the PDF file\n",
    "    fp = open(file_name, 'rb')\n",
    "\n",
    "    # Create a PDF parser object associated with the file object\n",
    "    parser = PDFParser(fp)\n",
    "\n",
    "    # Create a PDF document object that stores the document structure\n",
    "    document = PDFDocument(parser)\n",
    "\n",
    "    # Create a PDF resource manager object that stores shared resources\n",
    "    rsrcmgr = PDFResourceManager()\n",
    "\n",
    "    # Set parameters for analysis\n",
    "    laparams = LAParams()\n",
    "\n",
    "    # Create a PDF page aggregator object\n",
    "    device = PDFPageAggregator(rsrcmgr, laparams=laparams)\n",
    "    interpreter = PDFPageInterpreter(rsrcmgr, device)\n",
    "\n",
    "    # Save the output of the code to a list\n",
    "    output = []\n",
    "    for page in PDFPage.create_pages(document):\n",
    "        interpreter.process_page(page)\n",
    "        layout = device.get_result()\n",
    "        for obj in layout:\n",
    "            if hasattr(obj, \"get_text\"):\n",
    "                for line in obj:\n",
    "                    for char in line:\n",
    "                        if isinstance(char, LTChar):\n",
    "                            output.append((char.get_text(), char.fontname))\n",
    "\n",
    "    # Process the output word by word\n",
    "    bold_word = \"\"\n",
    "    italic_word = \"\"\n",
    "    nested_list = []\n",
    "    previous_font = \"\"\n",
    "\n",
    "    for char, font in output:\n",
    "        if \"Arial-BoldItalicMT\" in font:\n",
    "            if \"Arial-ItalicMT\" in previous_font:\n",
    "                nested_list.append([bold_word, italic_word])\n",
    "                bold_word = \"\"\n",
    "                italic_word = \"\"\n",
    "            bold_word += char\n",
    "            previous_font = font\n",
    "        elif \"Arial-ItalicMT\" in font:\n",
    "            italic_word += char\n",
    "            previous_font = font\n",
    "        else:\n",
    "            if bold_word:\n",
    "                nested_list.append([bold_word, italic_word])\n",
    "                bold_word = \"\"\n",
    "                italic_word = \"\"\n",
    "\n",
    "    # Check if there's any remaining text that needs to be added to the list\n",
    "    if bold_word:\n",
    "        nested_list.append([bold_word, italic_word])\n",
    "\n",
    "    # If the first element of a sublist is empty, but the second element isnt, add that to the second element of the previous sublist\n",
    "    final_list = []\n",
    "    for i in range(len(nested_list)):\n",
    "        stripped_first_elem = nested_list[i][0].strip()\n",
    "        if stripped_first_elem.startswith(\"ST\") or stripped_first_elem.startswith(\"Ratspräsident\") or stripped_first_elem.startswith('Pierre Heusser') or stripped_first_elem.startswith(\"Vizepräsident\") or stripped_first_elem.startswith('Pierre Heusser') or any(char.isdigit() for char in stripped_first_elem) == True:\n",
    "            continue\n",
    "            \n",
    "        elif nested_list[i][0].strip() == \"\" and nested_list[i][1].strip() != \"\":\n",
    "            if final_list:\n",
    "                final_list[-1][1] += nested_list[i][1]\n",
    "        \n",
    "        elif nested_list[i][0].strip() == \":\" and nested_list[i][1].strip() != \"\":\n",
    "            if final_list:\n",
    "                final_list[-1][1] += nested_list[i][1] \n",
    "                \n",
    "        elif nested_list[i][0].strip() == \".\":\n",
    "            if final_list:\n",
    "                final_list[-1][1] += nested_list[i][1]\n",
    "    \n",
    "        elif nested_list[i][0].strip() == \".\":\n",
    "            if final_list:\n",
    "                final_list[-1][1] += nested_list[i][1]\n",
    "        \n",
    "        elif nested_list[i][0].strip() != \"\" and nested_list[i][0][:2] != \"ST\":\n",
    "\n",
    "            final_list.append(nested_list[i])\n",
    "        \n",
    "    # Delete spaces at the beginning of the second element of every sublist\n",
    "    for i in range(len(final_list)):\n",
    "        final_list[i][1] = final_list[i][1].lstrip()\n",
    "        \n",
    "    # Delete \"Dr.\" ...\n",
    "    for i in range(len(final_list)):\n",
    "        final_list[i][0] = final_list[i][0].replace('Dr.', '')    \n",
    "        \n",
    "    final_list = [sublist for sublist in final_list if len(sublist[0]) >= 10]       \n",
    "\n",
    "    return final_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94b84dd4-be85-49c1-b39f-b489f53ef265",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lade Liste mit korrekten Namen und Parteien\n",
    "with open(\"list_file.txt\") as f:\n",
    "    name_list = f.read().splitlines()\n",
    "\n",
    "# Funktion,die Namen und Parteien der RednerInnen überprüft und falls nötig korrigiert\n",
    "# Input name = Vorname Name (Partei)\n",
    "# Output: korrekter Name und Partei Vorname Name (Partei)\n",
    "# Code: ChatGPT\n",
    "threshold=0.72\n",
    "def check_name_in_list(name):    \n",
    "    name = name.lstrip()\n",
    "    name = name.split(\")\")[0] + \")\"\n",
    "    if name in name_list:\n",
    "        return name\n",
    "    else:\n",
    "        closest_match = difflib.get_close_matches(name, name_list, n=1, cutoff=threshold)\n",
    "        if closest_match:\n",
    "            if threshold < 0.95:               \n",
    "                return closest_match[0]\n",
    "            else:                \n",
    "                return \"Incorrect\"\n",
    "        else:\n",
    "            return \"Incorrect\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81f269c9-06b2-4d1c-be9a-637d2f76a3b3",
   "metadata": {},
   "source": [
    "### 1.3.4 - Funktionen für Aufbau des dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fcf4629-ae56-4a80-913d-860fdce5d496",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Funktion, die aus der vorangehenden nested list mit den Voten ein erstes dataframe erstellt\n",
    "def build_initial_df (votelist):\n",
    "    df = pd.DataFrame(votelist)\n",
    "    return df\n",
    "\n",
    "#Funktion, welches die Textlängen der Voten zum df hinzufügt\n",
    "def add_length (intitial_df):   \n",
    "    initial_df['Länge'] = initial_df[1].apply(lambda x: len (x)) # Len ermitteln und neue Spalte bilden\n",
    "    return initial_df    \n",
    "\n",
    "#Funktion, welche die noch in den Namen enthaltenen Parteien absplittet und in eine eigene Spalte im df schiebt. Bereinigung einzelner Sonderfälle. \n",
    "def split_parties (df_with_length):\n",
    "    parteien = []\n",
    "    for values in df_with_length[0]:\n",
    "        #if values == 'David Garcia Nuñez':\n",
    "            #values = 'David Garcia Nuñez (AL)'\n",
    "        #elif values == 'Walter Anken':\n",
    "            #values = 'Walter Anken (SVP)'\n",
    "        #elif values == 'Sven Sobernheim':\n",
    "            #values = 'Sven Sobernheim (GLP)'               \n",
    "        \n",
    "        parteien.append(re.search(r'(?<=\\()(.+?)(?=\\))', values).group())\n",
    "    \n",
    "    df_with_length['Partei'] = parteien\n",
    "    \n",
    "    for values in df_with_length[0]:\n",
    "        if '(' in values and ')' in values:\n",
    "            partei = (re.search(r'(?<=\\()(.+?)(?=\\))', values))[1]\n",
    "            name_neu = values.replace('('+partei+')', '')\n",
    "            name_neu = name_neu.replace(':','')\n",
    "            name_neu = name_neu.strip()\n",
    "            name_ohne_partei.append(name_neu)\n",
    "        else:\n",
    "            name_neu = values.strip()\n",
    "            name_ohne_partei.append(name_neu)\n",
    "        \n",
    "    df_with_length[0] = name_ohne_partei\n",
    "    df_with_length[0] = df_with_length[0].str.strip()\n",
    "    \n",
    "    return df_with_length"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efaf3f5c-7a05-419c-b19e-649eb70965f1",
   "metadata": {},
   "source": [
    "### 1.3.5 Funktionen für Abfrage des Gemeinderats-API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "410be7ea-b979-4a40-b957-eb18504cb636",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Funktion, welche die Namen der RednerInnen aus dem df für die API-Abfrage aufbereitet\n",
    "def build_searchlist (df_with_corrnames):\n",
    "    search_list = []\n",
    "    names = df_with_corrnames[0].values.tolist()\n",
    "    names = [x.replace(' ','+') for x in names] # Space durch + ersetzen\n",
    "    parties = df_with_corrnames['Partei'].values.tolist()\n",
    "    search_list.extend([list(a) for a in zip(names, parties)])\n",
    "    return search_list\n",
    "\n",
    "# Suchabfrage nach Name\n",
    "# Das API ignoriert exakte Namen und Parteizugehörigtkeit und kann deshalbe falsche Treffer zurückgeben.\n",
    "def membersearch(name, partei):    \n",
    "    name = name.strip()\n",
    "    #if 'M ichael Schmid' in name:\n",
    "        #name.replace('M ichael Schmid', 'Michael Schmid')\n",
    "    pre_filtered = []\n",
    "    req = endpunkt_suche+'name='+name+'&parteiId='+partei+'&includeInactive=true'\n",
    "    r_suche = requests.get(req)\n",
    "    r_suche_out = r_suche.json()\n",
    "    for every in r_suche_out:\n",
    "        if every['Partei'] == partei:\n",
    "            pre_filtered.append(every)\n",
    "    \n",
    "    return pre_filtered    \n",
    "\n",
    "# Funktion die Suchresultate validiert  - welcher Name stimmt wirklich? \n",
    "# Es wird überprüft, ob Name und Partei des API-Resultats tatsächlich dem Input entspricht\n",
    "# Ausgegeben wird die MID des API, welches jedes Ratsmitglied eindeutig identifziert\n",
    "def memberselect (searchresult):\n",
    "    for every_result in searchresult:        \n",
    "        resname = every_result['Vorname']+' '+every_result['Name']        \n",
    "        snamrep = searchname.replace('+',' ')        \n",
    "        if resname == snamrep:        \n",
    "            corrid = every_result['Id']\n",
    "            return corrid\n",
    "\n",
    "# Funktion, die Mitgliederdetails anhand der ermittelten korrekten MID abfragt\n",
    "# Ausgeben wird eine Liste mit Anrede, Vorname, Name, Partei, Geburtstag, MID, sowie (zur Kontrolle) Name und Partei gemäss dataframe mit den Voten\n",
    "def memberget (mid):\n",
    "    type(mid)\n",
    "    url = endpunkt_abfrage+'mid='+mid\n",
    "    r = requests.get(url)\n",
    "    out = r.json()\n",
    "    vorname = out['Vorname']\n",
    "    name = out['Name']\n",
    "    partei = out['Partei']\n",
    "    nampi = vorname+' ' +name+partei\n",
    "    put = [out['Anrede'], out['Vorname'], out['Name'], out['Partei'], out['Geburtstag'], out['Id'], nampi]\n",
    "    \n",
    "    return put\n",
    "\n",
    "# Funktion, welche eine lokale Datenbank mit bereits früher abgefragten Mitgliederdetails abfragt. \n",
    "def query_nampi_dict (name,partei):\n",
    "    nampi = name+partei\n",
    "    output = nampi_dict[nampi]\n",
    "    return output\n",
    "\n",
    "# Funktion, welche einzelne Schritte/Funktionen zur Abfrage von Mitgliederdetails bündelt (check_nampi, quey_nampi, membersearch, memberselect und memberget)\n",
    "# Ausgegeben Ausgeben wird eine Liste [Anrede, Vorname, Name, Partei, Geburtstag, MID, Name und Partei gemäss dataframe mit den Voten]\n",
    "# Details zu jedem Ratsmitglied werden laufend in eine lokale Datenbank gespeichert\n",
    "# Die lokale Datenbank wird bei der Abfrage bevorzugt, da das API sehr träge ist. So wird jedes Mitglied nur ein einziges Mal über das API abgefragt.\n",
    "def membquest(name, partei):\n",
    "    name = name.replace(':', '')\n",
    "    name = name.strip()  \n",
    "    if partei == 'FPD':\n",
    "        partei = 'FDP'\n",
    "    nampi = name+partei\n",
    "    if nampi in nampi_dict:\n",
    "        put = query_nampi_dict (name, partei)\n",
    "        \n",
    "    else:\n",
    "        searchres = membersearch (name, partei)\n",
    "        midn = memberselect (searchres)    \n",
    "        put = memberget (midn)\n",
    "        nampi = name+partei\n",
    "        nampi_dict[nampi]=put\n",
    "    return put"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3979a097-f91f-426e-8034-f822ab9c5d2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Funktion, welche das bereits vorhandene df mit Voten, RednerInne, Längen, etc. aufräumt\n",
    "def clean_final_df (final_df):\n",
    "    final_df = final_df.iloc[:, [4,0,3,5,1,2,6,7]] # Reihenfolge der columns\n",
    "    final_df.columns = ['Anrede', 'Name', 'Partei', 'Geburtsdatum', 'Votum', 'Länge', 'Id', 'nampi'] # Beschriftung columns\n",
    "    final_df['Geburtsdatum'] =  pd.to_datetime(final_df['Geburtsdatum'], infer_datetime_format=True) # Geburtsdatum richtig setzen\n",
    "    return final_df               \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09886e95-e00c-48e8-8af3-103ff264952a",
   "metadata": {},
   "source": [
    "## 2 Code der die Funktionen ausführt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4e9a4f8-64e7-47a3-a8ce-ad6d24d4075f",
   "metadata": {},
   "source": [
    "### 2.1 load/init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75401be2-d62a-4c30-a9d6-cad705fa08da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lade (falls vorhanden) oder initialisiere uber_df, das df mit den Endresultaten\n",
    "if exists('uber_df.pickle') == True:\n",
    "    uber_df = uber_df_load()\n",
    "else:\n",
    "    uber_df = pd.DataFrame(columns=['Anrede','Name','Partei','Geburtsdatum','Sitzung','Länge','Id', 'nampi'])\n",
    "\n",
    "# Lade oder initialisere nampi_dict, die lokale Datenbank mit Details zu den Ratsmitgliedern\n",
    "if exists('nampi_dict.pickle') == True:\n",
    "    nampi_dict = nampi_dict_load()\n",
    "else:\n",
    "    nampi_dict = {} # key=nampi value=list'Anrede', 'Vorname', 'Name', 'Partei', 'Geburtstag', 'Id'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59b71d9e-e009-4eb9-add3-1686f9acddb4",
   "metadata": {},
   "source": [
    "### 2.2 Bündeln von Funktionen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "056b3cfc-ed36-42cc-a438-bd9f4c416481",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ausgegeben wird eine Liste von RednerInnen, deren Details abgefragt werden müssen sowie (mittels 'global') ein df mit den Voten und RednerInnen\n",
    "def part1 (every_pdf):\n",
    "    global sitzungs_id\n",
    "    sitzungs_id = ''.join(re.findall(r'[0-9]', every_pdf))\n",
    "    \n",
    "    final_list=extract_pdf_text(every_pdf)\n",
    "    \n",
    "    for i in range(len(final_list)):\n",
    "        final_list[i][0] = check_name_in_list(final_list[i][0])\n",
    "    \n",
    "    votelist = final_list\n",
    "    #save_votelist (votelist)\n",
    "        \n",
    "    global initial_df\n",
    "    initial_df = pd.DataFrame(votelist)\n",
    "    #initial_df = initial_df[initial_df[0].apply(lambda x: not x.startswith('ST'))]\n",
    "    #initial_df = initial_df[initial_df[0].apply(lambda x: not x.startswith('Pierre Heusser'))]\n",
    "    \n",
    "    #initial_df[0] = initial_df[0].apply(lambda x: x.replace(' :', ''))\n",
    "    #initial_df[0] = initial_df[0].apply(lambda x: x.replace(':', ''))\n",
    "    #initial_df[0] = initial_df[0].apply(lambda x: x.replace(' nimmt Stellung', ''))\n",
    "        \n",
    "    df_with_length = add_length(initial_df)\n",
    "    #save_vote_df(df_with_length)\n",
    "    \n",
    "    global name_ohne_partei\n",
    "    name_ohne_partei =[]\n",
    "    \n",
    "    global df_in_progress\n",
    "    df_in_progress = split_parties (df_with_length)\n",
    "       \n",
    "    search_list = build_searchlist (df_in_progress)\n",
    "    return search_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7fa2672-a247-4eff-bd19-0dcf888e7480",
   "metadata": {},
   "source": [
    "### 2.3 run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d0459aa-5ae1-488c-b0f4-b7b387294ae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Schlaufe, welche eine Liste mit den PDFs abarbeitet. \n",
    "# Endresultat ist das df mit allen Voten sowie Infos zu deren Länge und den RednerInnen\n",
    "for every_pdf in list_of_pdfs:\n",
    "    search_list = part1 (every_pdf)\n",
    "    resultlist = []\n",
    "    for every_name in search_list:\n",
    "        global searchname\n",
    "        searchname = every_name[0]\n",
    "        searchpartei = every_name[1]\n",
    "        outp = membquest (searchname, searchpartei)\n",
    "        resultlist.append(outp)\n",
    "        \n",
    "    nampi_dict_save()\n",
    "    \n",
    "    # Aufbau Resultate-df\n",
    "    result_df = pd.DataFrame(resultlist)    \n",
    "    result_df.drop(columns=[1,2,3], inplace=True)\n",
    "    final_df = pd.concat([df_in_progress, result_df], axis=1)\n",
    "    final_df = clean_final_df(final_df)\n",
    "    move_df = final_df.copy(deep=True)\n",
    "    \n",
    "    # Prep to move to uber_df\n",
    "    move_df.insert(4,'Sitzung','')\n",
    "    move_df['Sitzung'] = sitzungs_id\n",
    "    move_df.drop(['Votum'], axis=1, inplace=True)\n",
    "    \n",
    "    # !!! Index ist noch falsch, nicht fortlaufend\n",
    "    uber_df = uber_df.append(move_df)\n",
    "    #uber_df.reset_index()\n",
    "    uber_df_save()\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73cee634-9c74-489c-8f62-38aaa6ff7149",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
